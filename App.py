import streamlit as st
import requests
import matplotlib.pyplot as plt

# Define the ngrok URL
url = "https://eab2-34-16-216-78.ngrok-free.app/verify_and_check_bias"

# Streamlit app
st.title("AI vs Human Text Classification")
st.write("Enter a text to test whether it is generated by AI or a human.")

# Input text box
input_text = st.text_area("Input Text", height=200)
ai_score_threshold = st.slider("AI Score Threshold", 0.0, 1.0, 0.5)

if st.button("Classify"):
    if input_text:
        # Define the input data for AI classification
        input_data = {
            "text": input_text,
            "ai_score_threshold": ai_score_threshold
        }

        # Send a POST request to the endpoint
        response = requests.post(url, json=input_data)

        # Check the response status
        if response.status_code == 200:
            result = response.json()
            # Display the result as normal text
            classification = result.get("classification", "N/A")
            st.write("**Classification Result:**")
            st.write(f"Classification: {classification}")

            if classification == "AI Generated Text":
                # Define the input data for toxicity prediction
                response_toxicity = requests.post(url, json=input_data)

                # Check the response status
                if response_toxicity.status_code == 200:
                    result_toxicity = response_toxicity.json()
                    probability_of_toxicity = result_toxicity.get("probability_of_toxicity", 0.0)
                    prediction = result_toxicity.get("prediction", "N/A")

                    st.write(f"Prediction: {prediction}")

                    # Plot the circular progress chart for toxicity score
                    fig, ax = plt.subplots()
                    ax.pie([probability_of_toxicity, 1 - probability_of_toxicity], 
                           startangle=90, colors=['#FF6F61', '#E0E0E0'], 
                           wedgeprops={'width': 0.3})
                    ax.text(0, 0, f"{int(probability_of_toxicity * 100)}%", 
                            ha='center', va='center', fontsize=20, color='#FF6F61')
                    ax.set_aspect('equal')
                    st.pyplot(fig)
                else:
                    st.error("Error: Unable to classify the text for toxicity. Please try again later.")
        else:
            st.error("Error: Unable to classify the text. Please try again later.")
    else:
        st.warning("Please enter some text to classify.")
